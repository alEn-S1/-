#!/usr/bin/env python3
"""
æ£€æŸ¥Qwen3-4Bæ¨¡å‹é…ç½®ï¼ŒæŸ¥æ‰¾reasoning/thinkingç›¸å…³è®¾ç½®
"""

import json
from pathlib import Path

model_path = "/data/public/models/base/Qwen/Qwen3-4B"

print("ğŸ” æ£€æŸ¥Qwen3-4Bæ¨¡å‹é…ç½®")
print("="*70)

# 1. æ£€æŸ¥config.json
config_file = Path(model_path) / "config.json"
if config_file.exists():
    print("\nğŸ“„ config.json:")
    print("-"*70)
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    # æŸ¥æ‰¾reasoning/thinkingç›¸å…³é…ç½®
    keywords = ['reasoning', 'thinking', 'enable', 'chat_template']
    found_keys = []
    
    for key, value in config.items():
        key_lower = key.lower()
        if any(kw in key_lower for kw in keywords):
            found_keys.append((key, value))
            print(f"  {key}: {value}")
    
    if not found_keys:
        print("  âŒ æ²¡æœ‰æ‰¾åˆ°reasoning/thinkingç›¸å…³é…ç½®")
    
    # æ‰“å°å®Œæ•´é…ç½®ï¼ˆå‰20ä¸ªé”®ï¼‰
    print("\nğŸ“‹ å‰20ä¸ªé…ç½®é¡¹:")
    print("-"*70)
    for i, (key, value) in enumerate(list(config.items())[:20]):
        print(f"  {key}: {value}")

# 2. æ£€æŸ¥tokenizer_config.json
tokenizer_config_file = Path(model_path) / "tokenizer_config.json"
if tokenizer_config_file.exists():
    print("\nğŸ“„ tokenizer_config.json:")
    print("-"*70)
    with open(tokenizer_config_file, 'r') as f:
        tokenizer_config = json.load(f)
    
    # æŸ¥æ‰¾chat_template
    if 'chat_template' in tokenizer_config:
        chat_template = tokenizer_config['chat_template']
        print(f"  chat_templateé•¿åº¦: {len(chat_template)} å­—ç¬¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«thinkingç›¸å…³å†…å®¹
        if 'thinking' in chat_template.lower():
            print("  âœ… chat_templateåŒ…å«'thinking'å…³é”®è¯")
            # æ‰¾å‡ºç›¸å…³è¡Œ
            lines = chat_template.split('\n')
            for i, line in enumerate(lines):
                if 'thinking' in line.lower():
                    print(f"    è¡Œ{i}: {line[:100]}...")
        else:
            print("  âŒ chat_templateä¸åŒ…å«'thinking'å…³é”®è¯")
    
    # æŸ¥æ‰¾å…¶ä»–ç›¸å…³é…ç½®
    for key, value in tokenizer_config.items():
        key_lower = key.lower()
        if any(kw in key_lower for kw in ['reasoning', 'thinking', 'enable']):
            print(f"  {key}: {value}")

# 3. æ£€æŸ¥generation_config.json
gen_config_file = Path(model_path) / "generation_config.json"
if gen_config_file.exists():
    print("\nğŸ“„ generation_config.json:")
    print("-"*70)
    with open(gen_config_file, 'r') as f:
        gen_config = json.load(f)
    
    for key, value in gen_config.items():
        print(f"  {key}: {value}")

# 4. æµ‹è¯•tokenizerçš„å®é™…è¡Œä¸º
print("\nğŸ§ª æµ‹è¯•tokenizerå®é™…è¡Œä¸º:")
print("-"*70)

try:
    from transformers import AutoTokenizer
    
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    
    # æ£€æŸ¥tokenizerå±æ€§
    attrs = ['chat_template', 'eos_token', 'bos_token', 'pad_token']
    for attr in attrs:
        if hasattr(tokenizer, attr):
            value = getattr(tokenizer, attr)
            if isinstance(value, str) and len(value) > 100:
                print(f"  {attr}: {value[:100]}...")
            else:
                print(f"  {attr}: {value}")
    
    # å°è¯•ä¸åŒçš„apply_chat_templateè°ƒç”¨
    messages = [{"role": "user", "content": "æµ‹è¯•"}]
    
    print("\n  æµ‹è¯•1: é»˜è®¤")
    prompt1 = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    print(f"    é•¿åº¦: {len(prompt1)}")
    
    print("\n  æµ‹è¯•2: enable_thinking=False")
    try:
        prompt2 = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True,
            chat_template_kwargs={"enable_thinking": False}
        )
        print(f"    é•¿åº¦: {len(prompt2)}")
        print(f"    ä¸é»˜è®¤ç›¸åŒ: {prompt1 == prompt2}")
    except Exception as e:
        print(f"    âŒ å¤±è´¥: {e}")
    
    print("\n  æµ‹è¯•3: enable_thinking=True")
    try:
        prompt3 = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True,
            chat_template_kwargs={"enable_thinking": True}
        )
        print(f"    é•¿åº¦: {len(prompt3)}")
        print(f"    ä¸é»˜è®¤ç›¸åŒ: {prompt1 == prompt3}")
    except Exception as e:
        print(f"    âŒ å¤±è´¥: {e}")
    
except Exception as e:
    print(f"  âŒ åŠ è½½tokenizerå¤±è´¥: {e}")

print("\n" + "="*70)
print("æ£€æŸ¥å®Œæˆ")

