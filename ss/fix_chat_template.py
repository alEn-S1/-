#!/usr/bin/env python3
"""
æå–å¹¶æµ‹è¯•Qwen3-4Bçš„chat_templateï¼Œæ‰¾å‡ºenable_thinkingçš„é—®é¢˜
"""

from transformers import AutoTokenizer
import json

model_path = "/data/public/models/base/Qwen/Qwen3-4B"

print("ğŸ” æ·±å…¥åˆ†æchat_template")
print("="*70)

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

# 1. æå–å®Œæ•´çš„chat_template
chat_template = tokenizer.chat_template

print("\nğŸ“„ å®Œæ•´chat_templateå†…å®¹:")
print("-"*70)
print(chat_template)
print("-"*70)

# 2. æŸ¥æ‰¾enable_thinkingç›¸å…³çš„æ‰€æœ‰è¡Œ
print("\nğŸ” åŒ…å«'enable_thinking'çš„è¡Œ:")
print("-"*70)
lines = chat_template.split('\n')
for i, line in enumerate(lines, 1):
    if 'enable_thinking' in line.lower():
        print(f"è¡Œ{i}: {line}")

# 3. æ‰‹åŠ¨æµ‹è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
print("\nğŸ§ª æµ‹è¯•ä¸åŒçš„å‚æ•°ä¼ é€’æ–¹å¼:")
print("-"*70)

messages = [{"role": "user", "content": "1+1ç­‰äºå‡ ï¼Ÿ"}]

# æµ‹è¯•1: ä¸ä¼ å‚æ•°
print("\n1. ä¸ä¼ ä»»ä½•å‚æ•°:")
prompt1 = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
print(f"   Prompt: {prompt1}")
print(f"   é•¿åº¦: {len(prompt1)}")

# æµ‹è¯•2: enable_thinking=False
print("\n2. enable_thinking=False:")
try:
    prompt2 = tokenizer.apply_chat_template(
        messages, 
        tokenize=False, 
        add_generation_prompt=True,
        chat_template_kwargs={"enable_thinking": False}
    )
    print(f"   Prompt: {prompt2}")
    print(f"   é•¿åº¦: {len(prompt2)}")
    print(f"   ä¸é»˜è®¤ç›¸åŒ: {prompt1 == prompt2}")
except Exception as e:
    print(f"   âŒ å¤±è´¥: {e}")

# æµ‹è¯•3: enable_thinking=True
print("\n3. enable_thinking=True:")
try:
    prompt3 = tokenizer.apply_chat_template(
        messages, 
        tokenize=False, 
        add_generation_prompt=True,
        chat_template_kwargs={"enable_thinking": True}
    )
    print(f"   Prompt: {prompt3}")
    print(f"   é•¿åº¦: {len(prompt3)}")
    print(f"   ä¸é»˜è®¤ç›¸åŒ: {prompt1 == prompt3}")
except Exception as e:
    print(f"   âŒ å¤±è´¥: {e}")

# æµ‹è¯•4: å°è¯•å…¶ä»–å¯èƒ½çš„å‚æ•°å
print("\n4. å°è¯•å…¶ä»–å¯èƒ½çš„å‚æ•°:")
for param_name in ['reasoning', 'thinking', 'enable_reasoning', 'use_thinking']:
    try:
        prompt = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
            chat_template_kwargs={param_name: False}
        )
        if prompt != prompt1:
            print(f"   âœ… {param_name}=False æœ‰æ•ˆï¼ç”Ÿæˆçš„promptä¸åŒ")
            print(f"      é•¿åº¦: {len(prompt)}")
        else:
            print(f"   âŒ {param_name}=False æ— æ•ˆ")
    except Exception as e:
        print(f"   âŒ {param_name} æŠ¥é”™: {e}")

# 5. æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨messagesä¸­ä¼ é€’å‚æ•°
print("\n5. å°è¯•åœ¨messagesä¸­ä¼ é€’:")
try:
    messages_with_meta = [
        {"role": "user", "content": "1+1ç­‰äºå‡ ï¼Ÿ", "enable_thinking": False}
    ]
    prompt = tokenizer.apply_chat_template(
        messages_with_meta,
        tokenize=False,
        add_generation_prompt=True
    )
    if prompt != prompt1:
        print(f"   âœ… åœ¨messagesä¸­ä¼ é€’enable_thinkingæœ‰æ•ˆï¼")
        print(f"      Prompt: {prompt}")
    else:
        print(f"   âŒ åœ¨messagesä¸­ä¼ é€’æ— æ•ˆ")
except Exception as e:
    print(f"   âŒ å¤±è´¥: {e}")

print("\n" + "="*70)
print("åˆ†æå®Œæˆ")

# 6. ç»™å‡ºå»ºè®®
print("\nğŸ’¡ ç»“è®ºå’Œå»ºè®®:")
print("-"*70)
if prompt1 == prompt2 == prompt3:
    print("âŒ enable_thinkingå‚æ•°å®Œå…¨æ— æ•ˆ")
    print("\nå¯èƒ½çš„åŸå› :")
    print("1. Qwen3-4Bçš„chat_templateé€»è¾‘æœ‰é—®é¢˜")
    print("2. å‚æ•°ä¼ é€’æ–¹å¼ä¸å¯¹")
    print("3. å¯èƒ½éœ€è¦ç‰¹å®šçš„tokenizerç‰ˆæœ¬")
    print("\nå»ºè®®:")
    print("âœ… æ–¹æ¡ˆ1: æ‰‹åŠ¨ä¿®æ”¹promptï¼Œä¸ä¾èµ–chat_template_kwargs")
    print("âœ… æ–¹æ¡ˆ2: å‡çº§åˆ°Qwen2.5æˆ–æ›´æ–°ç‰ˆæœ¬ï¼ˆå¦‚æœæ”¯æŒï¼‰")
    print("âœ… æ–¹æ¡ˆ3: ç›´æ¥å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„thinkingè´¨é‡ï¼Œä¸æ§åˆ¶ç”Ÿæˆ")

